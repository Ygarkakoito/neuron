{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ygarkakoito/neuron/blob/main/%D0%95%D0%B3%D0%BE%D1%80%D0%BE%D0%B2%D0%B0_%D0%95%D0%B2%D0%B0_%D0%9F%D0%9821_2_%5B0%5D_Useful_tasks_(Exercises).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGEx8XBcLRn4"
      },
      "source": [
        "## Полезные задачки для дальнейшей работы с искусственными нейронными сетями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJOWwTELLRn7"
      },
      "source": [
        "## Работа с изображениями\n",
        "\n",
        "Все изображения представляют собой матрицы чисел (или многомерные векторы), которые кодируют цвета отдельных пикселей. Для изображений высоты $H$, ширины $W$ с $C$ цветовыми каналами получаем упорядоченный набор  $H \\times W \\times C$ чисел.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L01/out/img_to_array.png\" width=\"1000\" >\n",
        "\n",
        "Например, датасет CIFAR-10 содержит цветные (трехцветные) изображения размером $32 \\times 32$ пикселя. Таким образом, каждое изображение из датасета является точкой в $3072$-мерном ($32 \\times 32 \\times 3 = 3072$) вещественном пространстве.\n",
        "\n",
        "То есть все изображения по сути являются векторами, заполненными числами. В python есть несколько бибилиотек, которые отвечают за работу с векторами. Самыми часто используемыми для нейронных сетей -- библиотеки numpy и PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZOTiRFWLRn8"
      },
      "source": [
        "Посмотрим на одну из цифр из набора данных MNIST, как её видим мы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EGZwG0ICLRn9",
        "outputId": "d86f8356-30e5-43aa-9bdf-6426b32dad2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b1056e2e13e5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"assets/digit.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mimg_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'assets/digit.png'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = Image.open(\"assets/digit.png\")\n",
        "img_np = np.array(image)\n",
        "plt.imshow(img_np, cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDRWz0Z0LRoC"
      },
      "source": [
        "И как она записана в компьютере -- в виде набора векторов (матрицы):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neRaQ2NZLRoC",
        "outputId": "d9ef0260-7c53-45e4-b377-543736e3b6d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  12  15  20  12   1   0   0   0]\n",
            " [  0   0   0   0   0   0   3 123 225 242 255 225 137   7   0   0]\n",
            " [  0   0   0   0   0  15 207 251 103 109 107 105 171 145   0   0]\n",
            " [  0   0   0   0   0 149 236  80   0   0   0   0   4  21   0   0]\n",
            " [  0   0   0   0  16 228 106   0  17  33  17   0   0   0   0   0]\n",
            " [  0   0   0   0  97 248  98 138 232 255 216  22   0   0   0   0]\n",
            " [  0   0   0   0  50 247 255 197 111 123 252 129   0   0   0   0]\n",
            " [  0   0   0   0   1  54  55   9   0  49 250 116   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 158 240  44   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  88 255 125   0   0   0   0   0]\n",
            " [  0   0   0   0   7  15  23 132 255 188  12   0   0   0   0   0]\n",
            " [  0   0   0   0  20 200 229 240 157  28   0   0   0   0   0   0]\n",
            " [  0   0   0   0   3  64  73  45   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "print(img_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFZbtsSxLRoD"
      },
      "source": [
        "Подключить библиотеки numpy (для более короткой записи кода и простоты её полное название сокращают до np) и torch, чтобы обеспечить работу с векторами:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DltzFhvaLRoD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV3aezF1LRoD"
      },
      "source": [
        "Рассмотрим основные операции для работы с тензорами.\n",
        "Создать экземпляр класса [Tensor](https://pytorch.org/docs/stable/tensors.html#torch.Tensor).\n",
        "Определение из документации: A torch.Tensor is a multi-dimensional matrix containing elements of a single data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beWFyHOmLRoD",
        "outputId": "8e6ac30b-8153-44ff-f126-6bfc2cd780bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "e = torch.Tensor()\n",
        "e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alvv0ZpMLRoE"
      },
      "source": [
        "Записать вектор [1.1, 2.2, 3.2] в виде тензора и вывести его тип при помощи функции type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z5Y2miz4LRoE"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([1.1,2.,3,2])\n",
        "## WRITE YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGI0jNQNLRoE"
      },
      "source": [
        "Вопрос: чем принципиально отличаются записи a = torch.Tensor() и b = torch.tensor()? Что будет на выходе для a и для b?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "tn7dtwTeLRoE",
        "outputId": "1e2ddfa8-652c-43da-c0c5-1ceef8960f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:  tensor([])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9c08979f04f8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tensor() missing 1 required positional arguments: \"data\""
          ]
        }
      ],
      "source": [
        "a = torch.Tensor()\n",
        "print('a: ', a)\n",
        "b = torch.tensor()\n",
        "print(\"b: \", b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXhv3WvcLRoF"
      },
      "source": [
        "Создать тензор [1.1, 2.2, 3.2] указанного типа float64. Использовать параметр dtype:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiajHDsXLRoF",
        "outputId": "9c836f32-5f83-479b-cee2-2fb6ce5b7d55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "a = torch.tensor([1.1,2.,3,2])\n",
        "a.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaIVxCtPLRoF"
      },
      "source": [
        "Записать вектор [1.1, 2.2, 3.2] в виде тензора и вывести тип данных, которые помещены в тензор. Для этого так же использовать dtype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOifdWUYLRoF",
        "outputId": "430b0a5a-bc89-41fd-8314-16f28922310f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.5000, 2.5000],\n",
              "        [2.5000, 2.5000],\n",
              "        [2.5000, 2.5000]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "a = torch.full((3,2),2.5)\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGJgA_1BLRoF"
      },
      "source": [
        "Создать вектор размерности $3 \\times 2$ и заполнить его указанным значением 2.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "qFcT47_xLRoG",
        "outputId": "5b1165f6-c593-4b7d-c757-1e5026101e3c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2d957a961c11>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: full() received an invalid combination of arguments - got (size=tuple, ), but expected one of:\n * (tuple of ints size, Number fill_value, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, Number fill_value, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
          ]
        }
      ],
      "source": [
        "a = torch.full(size=(3,2))\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E89W3f15LRoG"
      },
      "source": [
        "Создать тензор размерности $3 \\times 2$ и заполнить его единицами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "JemjcQOyLRoG",
        "outputId": "e746ef3f-51cd-4f5c-ba0b-d3c2c4cd9d45"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6579926db06d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ones() received an invalid combination of arguments - got (tuple, float), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones((3,2),2.5)\n",
        "a\n",
        "a.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jroC44k5LRoH"
      },
      "source": [
        "Создать тензор размерности $2 \\times 3 \\times 4$ и заполнить его нулями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7ppUN5ULRoH",
        "outputId": "206e04c5-e448-43cf-8101-3ecbfc3bfcac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = ## WRITE YOUR CODE HERE\n",
        "b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbY2cOMLLRoI"
      },
      "source": [
        "Создать тензор размерности 3 строки и 4 стоблца, заполненный случайными числами."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKm4Cpj5LRoI",
        "outputId": "8ca735ce-a52a-46b5-aecc-4dd39f31dcf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.0881,  0.1997,  0.0820, -0.0912],\n",
              "        [ 1.2779,  0.0344, -2.1910, -2.4152],\n",
              "        [ 0.5511, -0.2265,  0.3425,  2.2303]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x = torch.randn(3,4)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuNVhP7uLRoI"
      },
      "source": [
        "Создать тензор - вектор размерности $1 \\times 5$, заполненный целыми случайными числами от 0 до 100."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD2SN2Z8LRoI",
        "outputId": "dd20d9a8-599d-41ec-b3f4-0c52de60f876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([96, 66,  3,  1, 76])\n"
          ]
        }
      ],
      "source": [
        "y = torch.randint(100,[5])\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLnv2FnYLRoJ"
      },
      "source": [
        "Создать вектор размерности $2 \\times 3$ и заполнить его целыми числами от -10 до 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLQSUHmHLRoJ",
        "outputId": "1b25d203-b2a4-4fb6-8229-7e4e18ccfa1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5, -2, -9],\n",
              "        [-9,  6, -8]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "a = torch.randint(-10,10,(2,3))\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GM3ve79LRoJ"
      },
      "source": [
        "Для того, чтобы все величины, которые мы создаём при помощи датчика случайных чисел, создались один раз и не изменяли своего значения, надо зафиксировать базовое число --- это делается при помощи функции torch.manual_seed().\n",
        "Функция torch.randn_like(x) возвращает тензор того же размера, что и x, который заполнен случайными числами из нормального распределения со средним 0 и дисперсией 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFtJoUalLRoJ",
        "outputId": "72eb4d8a-3a47-4586-db96-e0e043524af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a = tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]]),\n",
            "b = tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(7)\n",
        "a =torch.randn(1,5)\n",
        "b = torch.randn_like(a)\n",
        "print(f'a = {a},\\nb = {b}'.format(a, b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "othwHQBVLRoL"
      },
      "source": [
        "Создать вектор размерности $3 \\times 2$ и заполнить его указанным значением 2.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e39NYSzLRoL",
        "outputId": "eaf2af05-6371-4254-8e4c-381241fcf21c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.5000, 2.5000],\n",
              "        [2.5000, 2.5000],\n",
              "        [2.5000, 2.5000]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "a = torch.full((3,2),2.5)\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEmUNQTxLRoL"
      },
      "source": [
        "Для выполнения операций умножения на веса или на матрицы свёрток (для свёрточных нейронных сетей), необходимо вытянуть матрицу, которой представлено изображение:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zxX2HUTLRoL",
        "outputId": "7dacef29-742b-40d6-ecec-ec4cb90b037b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 15, 20, 12, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 123, 225, 242, 255, 225, 137, 7, 0, 0, 0, 0, 0, 0, 0, 15, 207, 251, 103, 109, 107, 105, 171, 145, 0, 0, 0, 0, 0, 0, 0, 149, 236, 80, 0, 0, 0, 0, 4, 21, 0, 0, 0, 0, 0, 0, 16, 228, 106, 0, 17, 33, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 97, 248, 98, 138, 232, 255, 216, 22, 0, 0, 0, 0, 0, 0, 0, 0, 50, 247, 255, 197, 111, 123, 252, 129, 0, 0, 0, 0, 0, 0, 0, 0, 1, 54, 55, 9, 0, 49, 250, 116, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 158, 240, 44, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 88, 255, 125, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 15, 23, 132, 255, 188, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 200, 229, 240, 157, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 64, 73, 45, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(ncols=2, figsize=(10, 4))\n",
        "ax[0].imshow(img_np, cmap=\"gray\")\n",
        "ax[1].imshow(img_np.reshape(1, -1), aspect=20, cmap=\"gray\")\n",
        "ax[0].set_title(\"Original image\")\n",
        "ax[1].set_title(\"Flattened image\")\n",
        "\n",
        "vector = np.array(image).flatten()\n",
        "print(list(vector))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvNp3FnWLRoM"
      },
      "source": [
        "Вытянуть тензор в одну линию можно при помощи функции flatten:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwpBZGFtLRoM",
        "outputId": "26d72acb-2f11-4568-aab1-0e3991f49471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 2])\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n"
          ]
        }
      ],
      "source": [
        "t = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "print(t.shape)\n",
        "print(torch.flatten(t))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvAoNf6vLRoM"
      },
      "source": [
        "Можно добавить в функцию flatten параметры, показывающие, с какого измерение по какое спрямлять тензор:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qclq_yoJLRoO",
        "outputId": "4b5ba6f6-f19e-4385-fdbf-8be56a0b8c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]]) torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "t_new = torch.flatten(t, start_dim=0, end_dim=1)\n",
        "print(t_new, t_new.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNOOBA9jLRoP"
      },
      "source": [
        "Ещё есть возможность, позволяющая представить вектор x в виде одномерного вектора (вытянуть в линию и в столбик все значения x) при помощи функции view:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXRqsqraLRoP",
        "outputId": "e5635086-47fa-422e-f15d-70dd53e10a43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-1.1434, -0.1035,  0.5756, -1.5654,  0.2323,  0.5961,  0.1848,  0.3316,\n",
            "         -0.1153, -0.2433,  1.0107,  0.2711]]) \n",
            " tensor([[-1.1434],\n",
            "        [-0.1035],\n",
            "        [ 0.5756],\n",
            "        [-1.5654],\n",
            "        [ 0.2323],\n",
            "        [ 0.5961],\n",
            "        [ 0.1848],\n",
            "        [ 0.3316],\n",
            "        [-0.1153],\n",
            "        [-0.2433],\n",
            "        [ 1.0107],\n",
            "        [ 0.2711]])\n"
          ]
        }
      ],
      "source": [
        "x_row = x.view(-1, 12)\n",
        "x_column = x.view(12, -1)\n",
        "print(x_row,'\\n',x_column)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VCSQrs5LRoP"
      },
      "source": [
        "В целом функция view может поменять форму тензора на любую допустимую. Изменить форму вектора x на $2 \\times 6$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bklEwysLRoQ",
        "outputId": "b9fb58dc-1abd-4124-9f2f-7646e3274e0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.0881,  0.1997],\n",
              "         [ 0.0820, -0.0912]],\n",
              "\n",
              "        [[ 1.2779,  0.0344],\n",
              "         [-2.1910, -2.4152]],\n",
              "\n",
              "        [[ 0.5511, -0.2265],\n",
              "         [ 0.3425,  2.2303]]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "x = x.view(3,2,2)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv-za4VXLRoQ"
      },
      "source": [
        "## Операции умножения внутри нейрона\n",
        "\n",
        "Модель нейрона взята из биологии и структура повторяет процесс передачи информации через нейрон. Входной сигнал обрабатывается и дальше принимается решение, насколько он важен и передавать ли его дальше.\n",
        "\n",
        "![Neuron.png](attachment:Neuron.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-AysSgRLRoQ"
      },
      "source": [
        "Та же логика ипользовалась при создании модели искусственного нейрона: входные данные умножаются на веса, передаются функции активации, которая их преобразует и передаёт дальше:\n",
        "![NN_sheme_with_biology.png](attachment:NN_sheme_with_biology.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmWjPF3bLRoQ"
      },
      "source": [
        "При перемножении заданных значений на веса необходимо использовать векторное произведение.\n",
        "Создать два тензора размера $2 \\times 3$ и $3 \\times 5$ и векторно перемножить их. Вывести на экран результирующий тензор и его размерность."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igtlHXB6LRoQ",
        "outputId": "c05b1699-0ead-456a-d052-e259db2ee244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2343, -2.1591, -1.6033,  0.5068, -0.0822],\n",
            "        [ 0.4111, -1.4498, -0.9561,  0.7538,  2.2104]]) \n",
            " torch.Size([2, 5])\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(2,3)\n",
        "b = torch.randn(3,5)\n",
        "res = a@b\n",
        "print(res,'\\n',res.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufiKQAIQLRoR"
      },
      "source": [
        "При умножении на веса бывает необходимо транспонировать данные (поменять порядок расположения осей).\n",
        "Изменить порядок расположения осей тензора x (транспонировать) можно двумя способами: при помощи  метода T и функции transpose()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kDPJMKzyLRoR",
        "outputId": "297a75bc-c87d-47cd-c318-12510be550d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный тензор x:\n",
            "tensor([[ 0.6899,  0.2273, -1.1037],\n",
            "        [ 0.3797,  0.6691,  0.4125]])\n",
            "\n",
            "Транспонированный тензор a (с использованием метода T):\n",
            "tensor([[ 0.6899,  0.3797],\n",
            "        [ 0.2273,  0.6691],\n",
            "        [-1.1037,  0.4125]])\n",
            "\n",
            "Исходный тензор x:\n",
            "tensor([[ 0.6899,  0.2273, -1.1037],\n",
            "        [ 0.3797,  0.6691,  0.4125]])\n",
            "\n",
            "Транспонированный тензор b (с использованием функции transpose()):\n",
            "tensor([[ 0.6899,  0.3797],\n",
            "        [ 0.2273,  0.6691],\n",
            "        [-1.1037,  0.4125]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(2, 3)\n",
        "\n",
        "# Транспонирование с использованием метода T\n",
        "a = x.T\n",
        "\n",
        "# Вывести исходный и транспонированный тензор\n",
        "print(\"Исходный тензор x:\")\n",
        "print(x)\n",
        "print(\"\\nТранспонированный тензор a (с использованием метода T):\")\n",
        "print(a)\n",
        "\n",
        "# Транспонирование с использованием функции transpose()\n",
        "b = x.transpose(0, 1)  # Меняем порядок осей 0 и 1\n",
        "\n",
        "# Вывести исходный и транспонированный тензор\n",
        "print(\"\\nИсходный тензор x:\")\n",
        "print(x)\n",
        "print(\"\\nТранспонированный тензор b (с использованием функции transpose()):\")\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko9TtNaMLRoR"
      },
      "source": [
        "Найти сумму всех элементов тензора a."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JC91eL6TLRoR",
        "outputId": "1650ae6e-9e64-495d-e7ea-06f75be8d160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сумма всех элементов тензора a (с использованием метода .sum()): tensor(1.6739)\n",
            "Сумма всех элементов тензора a (с использованием функции torch.sum()): tensor(1.6739)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Найти сумму всех элементов с использованием метода .sum()\n",
        "sum_a = a.sum()\n",
        "\n",
        "# Вывести сумму\n",
        "print(\"Сумма всех элементов тензора a (с использованием метода .sum()):\", sum_a)\n",
        "\n",
        "# Найти сумму всех элементов с использованием функции torch.sum()\n",
        "sum_a_function = torch.sum(a)\n",
        "\n",
        "print(\"Сумма всех элементов тензора a (с использованием функции torch.sum()):\", sum_a_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syWctEXwLRoS"
      },
      "source": [
        "Найти сумму всех элементов тензора a по строкам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Yn0ntV2rLRoS",
        "outputId": "9d87940d-350d-43fa-8a02-14aab1b3a552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сумма элементов по строкам:\n",
            "tensor([-0.7485,  2.4224])\n"
          ]
        }
      ],
      "source": [
        "# Найти сумму элементов по строкам (по каждой строке отдельно)\n",
        "sum_a_by_rows = torch.sum(a, dim=1)\n",
        "\n",
        "print(\"Сумма элементов по строкам:\")\n",
        "print(sum_a_by_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4E7pOQXLRoS"
      },
      "source": [
        "Найти сумму всех элементов тензора a по столбцам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "n3jk2t45LRoS",
        "outputId": "98c6e958-a3a7-4ee5-e2c0-91905ba6c6f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Сумма элементов по столбцам:\n",
            "tensor([0.3357, 0.1826, 1.1556])\n"
          ]
        }
      ],
      "source": [
        "sum_a_by_columns = torch.sum(a, dim=0)\n",
        "\n",
        "print(\"Сумма элементов по столбцам:\")\n",
        "print(sum_a_by_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQWJfI5ALRoT"
      },
      "source": [
        "Найти максимальные значения вектора x по столбцам и строкам при помощи функции max."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "V8aCWKjGLRoT",
        "outputId": "36d46176-3860-4083-bb7f-3bcb9ae1a311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Максимальные значения по строкам:\n",
            "tensor([0.6899, 0.6691])\n",
            "\n",
            "Максимальные значения по столбцам:\n",
            "tensor([0.6899, 0.6691, 0.4125])\n"
          ]
        }
      ],
      "source": [
        "# Найти максимальные значения по строкам и столбцам\n",
        "max_values_rows, _ = x.max(dim=1)  # Максимум по строкам, используя _ для игнорирования индексов\n",
        "max_values_columns, _ = x.max(dim=0)  # Максимум по столбцам, используя _ для игнорирования индексов\n",
        "\n",
        "print(\"Максимальные значения по строкам:\")\n",
        "print(max_values_rows)\n",
        "print(\"\\nМаксимальные значения по столбцам:\")\n",
        "print(max_values_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVVoallMLRoT"
      },
      "source": [
        "Создать два тензора [[5, 0, 1], [6, 0, 2]] и [[2, 3, 0], [3, 4, 5]]. Найти максимум из двух тензоров на каждом месте при помощи функции maximum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VnE_7faeLRoT",
        "outputId": "8f4cdd98-0201-4bf5-b115-8b5201a9d09a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Максимум из двух тензоров:\n",
            "tensor([[5, 3, 1],\n",
            "        [6, 4, 5]])\n"
          ]
        }
      ],
      "source": [
        "tensor1 = torch.tensor([[5, 0, 1], [6, 0, 2]])\n",
        "tensor2 = torch.tensor([[2, 3, 0], [3, 4, 5]])\n",
        "\n",
        "\n",
        "max_tensor = torch.maximum(tensor1, tensor2)\n",
        "\n",
        "print(\"Максимум из двух тензоров:\")\n",
        "print(max_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD1NAtfTLRoU"
      },
      "source": [
        "В разных библиотеках наборы данных изображений обрабатываются в разных форматах:\n",
        "\n",
        "OpenCV, TensorFlow, Pillow, etc. : `Batch x Height x Width x Channels`\n",
        "\n",
        "PyTorch : `Batch x Channels x Height x Width`\n",
        "\n",
        "Поэтому периодически возникает необходимость менять местами измерения или убирать какие-то измерения."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7KjIAT6LRoU"
      },
      "source": [
        "Создать тензор a размерности $(2, 5, 1, 8)$, заполнить его нулями и поменять местами его измерения $(0, 1, 2, 3) \\to (2, 0, 3, 1)$ при помощи функции permute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PO8uTxCoLRoU",
        "outputId": "4e6170f8-4f3b-4a8d-fe89-93e5ace6efa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность исходного тензора: torch.Size([2, 5, 1, 8])\n",
            "Размерность переставленного тензора: torch.Size([1, 2, 8, 5])\n"
          ]
        }
      ],
      "source": [
        "a = torch.zeros((2, 5, 1, 8))\n",
        "a_permuted = a.permute(2, 0, 3, 1)\n",
        "\n",
        "print(\"Размерность исходного тензора:\", a.size())\n",
        "print(\"Размерность переставленного тензора:\", a_permuted.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWlrfsZFLRoU"
      },
      "source": [
        "\n",
        "Создать тензор b размерности $(2, 5, 1, 8)$, заполнить его единицами и поменять местами его измерения $(0, 1, 2, 3) \\to (1, 2, 0, 3)$ при помощи функции transpose из библиотеки numpy. Вывести результат на экран:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "YYHrnSk7LRoU",
        "outputId": "28a4f831-cf86-4df0-b9e9-f40afb35086a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность исходного тензора: (2, 5, 1, 8)\n",
            "Размерность переставленного тензора: (5, 1, 2, 8)\n"
          ]
        }
      ],
      "source": [
        "b = np.ones((2, 5, 1, 8))\n",
        "\n",
        "b_transposed = np.transpose(b, (1, 2, 0, 3))\n",
        "\n",
        "print(\"Размерность исходного тензора:\", b.shape)\n",
        "print(\"Размерность переставленного тензора:\", b_transposed.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgfGp_mdLRoV"
      },
      "source": [
        "Удалить измерение, равное 1, у вектора a при помощи функции squeeze:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "G1PP8rN2LRoV",
        "outputId": "b524db16-299f-4061-ec5a-e8b97df7420a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность исходного тензора: torch.Size([2, 5, 1, 8])\n",
            "Размерность уменьшенного тензора: torch.Size([2, 5, 8])\n"
          ]
        }
      ],
      "source": [
        "a = torch.zeros((2, 5, 1, 8))\n",
        "\n",
        "a_squeezed = a.squeeze()\n",
        "\n",
        "print(\"Размерность исходного тензора:\", a.size())\n",
        "print(\"Размерность уменьшенного тензора:\", a_squeezed.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ29RM47LRoV"
      },
      "source": [
        "Добавить ещё одно измерение для тензора a и поставить его на место 1 при помощи функции unsqueeze:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7Mrr2IZcLRoV",
        "outputId": "8d1cebdf-e7e3-4cb9-be4b-074cf32bd7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность исходного тензора: torch.Size([2, 5, 8])\n",
            "Размерность расширенного тензора: torch.Size([2, 1, 5, 8])\n"
          ]
        }
      ],
      "source": [
        "a = torch.zeros((2, 5, 8))\n",
        "\n",
        "a_unsqueezed = a.unsqueeze(1)  # Добавляем новое измерение на место 1\n",
        "\n",
        "\n",
        "print(\"Размерность исходного тензора:\", a.size())\n",
        "print(\"Размерность расширенного тензора:\", a_unsqueezed.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0VmVsMNLRoW"
      },
      "source": [
        "Функция transpose может поменять местами два указанных измерения. Создать вектор размерности $2 \\times 2 \\times 3$ и поменять местами измерения 1 и 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iPw9cAqJLRoW",
        "outputId": "88dfbec9-5b19-4d2a-a0f2-ac865e349583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность исходного вектора: torch.Size([2, 2, 3])\n",
            "Размерность переставленного вектора: torch.Size([2, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn(2, 2, 3)\n",
        "\n",
        "x_transposed = x.transpose(1, 2)\n",
        "\n",
        "print(\"Размерность исходного вектора:\", x.size())\n",
        "print(\"Размерность переставленного вектора:\", x_transposed.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTLPSzj7LRoW"
      },
      "source": [
        "Для подсчёта точности модели бывает необходимо сравнить совпадение вектора с метками данных с выходными (предсказанными значениями).\n",
        "Посчитать количество совпадений (на одинаковых местах одинаковые числа) для двух векторов [9, 4, 3, 9, 6] и [5, 4, 5, 9, 4]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kZmT7ebuLRoW",
        "outputId": "2fdc4a91-fc8e-4a16-db50-d62493ecf35d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество совпадений: 2\n"
          ]
        }
      ],
      "source": [
        "vector1 = np.array([9, 4, 3, 9, 6])\n",
        "vector2 = np.array([5, 4, 5, 9, 4])\n",
        "\n",
        "matching_elements = np.sum(vector1 == vector2)\n",
        "\n",
        "print(\"Количество совпадений:\", matching_elements)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z20RvbKLLRoX"
      },
      "source": [
        "Чтобы обратиться к элементу тензора, надо указать в скобках его индекс, но в таком случае получим tensor(int). Чтобы получить значение элемента, надо использовать метод item.\n",
        "Создать тензор $[6, 6, 7, 2, 7, 9, 1, 5]$ и найти его 2й элемент, и значение 2го элемента:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hk2K0wuuLRoY",
        "outputId": "b11631eb-13de-4b8f-f7c6-8819d3e3aa70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Индекс 2-го элемента: 1\n",
            "Значение 2-го элемента: 6\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.tensor([6, 6, 7, 2, 7, 9, 1, 5])\n",
        "\n",
        "# 2-й элемент (по индексу)\n",
        "element_at_index_2 = tensor[1]\n",
        "\n",
        "#  значение 2-го элемента\n",
        "value_of_element_at_index_2 = element_at_index_2.item()\n",
        "\n",
        "print(\"Индекс 2-го элемента:\", 1)\n",
        "print(\"Значение 2-го элемента:\", value_of_element_at_index_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2QGzR9hLRoZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}